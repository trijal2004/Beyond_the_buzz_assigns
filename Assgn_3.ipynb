{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import random\n",
    "\n",
    "from torch.functional import F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_to_names(fname):\n",
    "    EOS = \"<EOS>\"\n",
    "    data = []\n",
    "        \n",
    "    text = open(fname).read().lower()\n",
    "            \n",
    "    names = text.splitlines()\n",
    "    for i, name in enumerate(names): \n",
    "        ch_list = list(name) + [EOS]\n",
    "        data.append(ch_list)\n",
    "    return data\n",
    "names = split_to_names(r\"C:\\Users\\Trijal Srivastava\\OneDrive\\Desktop\\VS CODE\\Beyond the buzz\\RNN\\dinos (1).txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "char_vocab = [\"<EOS>\"] + sorted([ch for ch in string.ascii_lowercase])\n",
    "char_to_ix = {ch:i for i,ch in enumerate(char_vocab)}\n",
    "ix_to_char = {i:ch for ch,i in char_to_ix.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_as_str, _map):\n",
    "        self.data_as_int = []\n",
    "        \n",
    "        # Convert characters to integers\n",
    "        for seq_as_str in data_as_str:\n",
    "            seq_as_int = keys_to_values(seq_as_str, _map,\n",
    "                random.choice(list(_map)))\n",
    "            \n",
    "            self.data_as_int.append(seq_as_int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_as_int)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        # Get data sample at index ix\n",
    "        item = self.data_as_int[ix]\n",
    "        \n",
    "        # Slice x and y from sample\n",
    "        x = item[:-1]\n",
    "        y = item[ 1:]\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "def keys_to_values(keys, _map, default):\n",
    "    return [_map.get(key, default) for key in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(names, char_to_ix)\n",
    "dataloader = DataLoader(dataset, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, _map, hidden_size, emb_dim=8, n_layers=1, dropout_p=0.2):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.vocab_size  = len(_map)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_dim     = emb_dim\n",
    "        self.n_layers    = n_layers\n",
    "        self.dropout_p   = dropout_p\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=self.vocab_size,\n",
    "            embedding_dim =self.emb_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size =self.emb_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers =self.n_layers,\n",
    "            batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            in_features =self.hidden_size,\n",
    "            out_features=self.vocab_size)\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        n_b, n_s = x.shape\n",
    "        \n",
    "        embed = self.embedding(x)\n",
    "        yhat, state = self.lstm(embed, prev_state)\n",
    "        \n",
    "        yhat = self.dropout(yhat)\n",
    "        out = self.fc(yhat)\n",
    "        return out, state\n",
    "    \n",
    "    def init_state(self, b_size=1):\n",
    "        return (torch.zeros(self.n_layers, b_size, self.hidden_size),\n",
    "                torch.zeros(self.n_layers, b_size, self.hidden_size))\n",
    "\n",
    "model = Model(char_to_ix, 64, 8, n_layers=1, dropout_p=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   1000/50000, Loss:   2.4220\n",
      "Iteration:   2000/50000, Loss:   2.0090\n",
      "Iteration:   3000/50000, Loss:   1.8742\n",
      "Iteration:   4000/50000, Loss:   1.7780\n",
      "Iteration:   5000/50000, Loss:   1.7585\n",
      "Iteration:   6000/50000, Loss:   1.7220\n",
      "Iteration:   7000/50000, Loss:   1.6466\n",
      "Iteration:   8000/50000, Loss:   1.6684\n",
      "Iteration:   9000/50000, Loss:   1.6105\n",
      "Iteration:  10000/50000, Loss:   1.5923\n",
      "Iteration:  11000/50000, Loss:   1.5850\n",
      "Iteration:  12000/50000, Loss:   1.5743\n",
      "Iteration:  13000/50000, Loss:   1.5263\n",
      "Iteration:  14000/50000, Loss:   1.5551\n",
      "Iteration:  15000/50000, Loss:   1.5016\n",
      "Iteration:  16000/50000, Loss:   1.5044\n",
      "Iteration:  17000/50000, Loss:   1.4913\n",
      "Iteration:  18000/50000, Loss:   1.4513\n",
      "Iteration:  19000/50000, Loss:   1.4622\n",
      "Iteration:  20000/50000, Loss:   1.4577\n",
      "Iteration:  21000/50000, Loss:   1.4123\n",
      "Iteration:  22000/50000, Loss:   1.4419\n",
      "Iteration:  23000/50000, Loss:   1.4023\n",
      "Iteration:  24000/50000, Loss:   1.3990\n",
      "Iteration:  25000/50000, Loss:   1.3612\n",
      "Iteration:  26000/50000, Loss:   1.3910\n",
      "Iteration:  27000/50000, Loss:   1.3490\n",
      "Iteration:  28000/50000, Loss:   1.3665\n",
      "Iteration:  29000/50000, Loss:   1.3368\n",
      "Iteration:  30000/50000, Loss:   1.3440\n",
      "Iteration:  31000/50000, Loss:   1.3067\n",
      "Iteration:  32000/50000, Loss:   1.3187\n",
      "Iteration:  33000/50000, Loss:   1.2819\n",
      "Iteration:  34000/50000, Loss:   1.3161\n",
      "Iteration:  35000/50000, Loss:   1.2994\n",
      "Iteration:  36000/50000, Loss:   1.2721\n",
      "Iteration:  37000/50000, Loss:   1.2718\n",
      "Iteration:  38000/50000, Loss:   1.2551\n",
      "Iteration:  39000/50000, Loss:   1.2740\n",
      "Iteration:  40000/50000, Loss:   1.2497\n",
      "Iteration:  41000/50000, Loss:   1.2476\n",
      "Iteration:  42000/50000, Loss:   1.2048\n",
      "Iteration:  43000/50000, Loss:   1.2489\n",
      "Iteration:  44000/50000, Loss:   1.2304\n",
      "Iteration:  45000/50000, Loss:   1.2132\n",
      "Iteration:  46000/50000, Loss:   1.2052\n",
      "Iteration:  47000/50000, Loss:   1.1840\n",
      "Iteration:  48000/50000, Loss:   1.2093\n",
      "Iteration:  49000/50000, Loss:   1.1972\n",
      "Iteration:  50000/50000, Loss:   1.1789\n"
     ]
    }
   ],
   "source": [
    "def train(model, data, num_iter, criterion, clip=0.25, lr=0.001, print_every=50):\n",
    "    model.train()\n",
    "    \n",
    "    costs = []\n",
    "    running_loss = 0\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    curr_iter = 0\n",
    "    while curr_iter<num_iter:\n",
    "        for x, y in data:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Initialise model's state and perform forward-prop\n",
    "            prev_state = model.init_state(b_size=x.shape[0])\n",
    "            out, state = model(x, prev_state)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(out.transpose(1, 2), y)\n",
    "            costs.append(loss.item())\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate gradients and update parameters\n",
    "            loss.backward()\n",
    "            if clip:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            curr_iter += 1\n",
    "            if print_every and (curr_iter%print_every)==0:\n",
    "                print(\"Iteration: {:{}}/{}, Loss: {:8.4f}\".format(\n",
    "                    curr_iter, int(math.log(num_iter, 10))+2, num_iter,\n",
    "                    running_loss/float(print_every)))\n",
    "                running_loss = 0\n",
    "                \n",
    "            if curr_iter>=num_iter:\n",
    "                break\n",
    "    return model, costs\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model, costs = train(\n",
    "    model, dataloader , 50000, criterion, clip=0.25, lr=1e-3, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next(model, x, prev_state, topk=5, uniform=True):\n",
    "    # Perform forward-prop and get the output of the last time-step\n",
    "    out, state = model(x, prev_state)\n",
    "    last_out = out[0, -1, :]\n",
    "\n",
    "    # Get the top-k indexes and their values\n",
    "    topk = topk if topk else last_out.shape[0]\n",
    "    top_logit, top_ix = torch.topk(last_out, k=topk, dim=-1)\n",
    "    \n",
    "    # Get the softmax of the topk's and sample\n",
    "    p = None if uniform else F.softmax(top_logit.detach(), dim=-1).numpy()\n",
    "    sampled_ix = np.random.choice(top_ix, p=p)\n",
    "    return sampled_ix, state\n",
    "\n",
    "\n",
    "def sample(model, seed, topk=5, uniform=True, max_seqlen=18, stop_on=None):\n",
    "    seed = seed if isinstance(seed, (list, tuple)) else [seed]\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sampled_ix_list = seed[:]\n",
    "        x = torch.tensor([seed])\n",
    "        \n",
    "        prev_state = model.init_state(b_size=1)\n",
    "        for t in range(max_seqlen - len(seed)):\n",
    "            sampled_ix, prev_state = sample_next(model, x, prev_state, topk, uniform)\n",
    "\n",
    "            sampled_ix_list.append(sampled_ix)\n",
    "            x = torch.tensor([[sampled_ix]])\n",
    "            \n",
    "            if sampled_ix==stop_on:\n",
    "                break\n",
    "    \n",
    "    model.train()\n",
    "    return sampled_ix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Samples where seed is a randomly chosen character.\n",
      "5 => e o m a s a u r u s <EOS>\n",
      "24 => x i a n z u s a u r u s <EOS>\n",
      "7 => g u l u a n <EOS>\n",
      "14 => n e o d r o m u s <EOS>\n",
      "5 => e u r o p e l t a <EOS>\n",
      "13 => m o n g o s a u r u s <EOS>\n",
      "5 => e u l o r n i t h o u s <EOS>\n",
      "11 => k u n g i n i n s a u r u s <EOS>\n",
      "16 => p o r a c h i o s a u r u s <EOS>\n",
      "19 => s a u r o s a u r u s <EOS>\n",
      ">>> Samples where seed is a list of character.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'<PAD>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m>>> Samples where seed is a list of character.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     seed \u001b[39m=\u001b[39m keys_to_values(\u001b[39mlist\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m), char_to_ix, char_to_ix[\u001b[39m\"\u001b[39;49m\u001b[39m<PAD>\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(seed, \u001b[39m\"\u001b[39m\u001b[39m=>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(keys_to_values(\n\u001b[0;32m     13\u001b[0m         sample(model, seed, \u001b[39m5\u001b[39m, \u001b[39mFalse\u001b[39;00m, \u001b[39m30\u001b[39m, char_to_ix[\u001b[39m\"\u001b[39m\u001b[39m<EOS>\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[0;32m     14\u001b[0m         ix_to_char, \u001b[39m\"\u001b[39m\u001b[39m<?>\u001b[39m\u001b[39m\"\u001b[39m)))\n",
      "\u001b[1;31mKeyError\u001b[0m: '<PAD>'"
     ]
    }
   ],
   "source": [
    "print(\">>> Samples where seed is a randomly chosen character.\")\n",
    "for i in range(10):\n",
    "    seed = random.choice(list(char_to_ix.values())[1:])\n",
    "    print(seed, \"=>\", \" \".join(keys_to_values(\n",
    "        sample(model, seed, 5, False, 30, char_to_ix[\"<EOS>\"]),\n",
    "        ix_to_char, \"<?>\")))\n",
    "\n",
    "\n",
    "print(\">>> Samples where seed is a list of character.\")\n",
    "for i in range(3):\n",
    "    seed = keys_to_values(list(\"python\"), char_to_ix, char_to_ix[\"<PAD>\"])\n",
    "    print(seed, \"=>\", \"\".join(keys_to_values(\n",
    "        sample(model, seed, 5, False, 30, char_to_ix[\"<EOS>\"]),\n",
    "        ix_to_char, \"<?>\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
